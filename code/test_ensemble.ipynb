{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Im0GS6I0q7Rw",
    "outputId": "7106c86a-dc70-47d8-8777-5af7ff0c7359"
   },
   "outputs": [],
   "source": [
    "%pip install transformers\n",
    "%pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from wandb_helper import init_wandb\n",
    "import wandb_helper\n",
    "import wandb\n",
    "from state import State\n",
    "\n",
    "config = config.get_default_config()\n",
    "wandb_helper.login(config)\n",
    "state = State(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.load_train_nbs_range(from_=100000, to_=105000)\n",
    "# state.load_train_nbs_tail(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_model\n",
    "from graph_model import MyGraphModel\n",
    "\n",
    "\n",
    "graph3_model = MyGraphModel(state, preload_state=\"graph-model-100k-ncs=2.bin\")\n",
    "graph3_model.to(state.device)\n",
    "print('Graph3 model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unixcoder\n",
    "\n",
    "unixcoder_model = unixcoder.reload_model(state, \"model-epoch1.5.bin\")\n",
    "print('Unixcoder model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unixcoder\n",
    "import simple_ensemble\n",
    "\n",
    "if state.config.use_simple_ensemble_model:\n",
    "    ensemble_model = simple_ensemble.SimpleEnsembleModel(state, state_dict='simple-ensemble-model-1k-strange.bin')\n",
    "else:\n",
    "    ensemble_model = unixcoder.EnsembleModel(state, state_dict='ensemble-model-1k.bin')\n",
    "print('Ensemble model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import metric\n",
    "from metric import Score\n",
    "from common import get_code_cells, get_markdown_cells\n",
    "from dataclasses import dataclass\n",
    "import wandb\n",
    "from graph_model import Sample\n",
    "import numpy as np\n",
    "import torch\n",
    "import ensembles\n",
    "from ensembles import gen_samples\n",
    "from common import split_into_batches, OneCell\n",
    "\n",
    "from cosine_train import end_token\n",
    "from common import sim\n",
    "import math\n",
    "\n",
    "def get_probs_by_embeddings(embeddings, m_cell_id, code_cell_ids, coef_mul):\n",
    "    markdown_emb = embeddings[m_cell_id]\n",
    "    sims = [sim(markdown_emb, embeddings[c]) for c in code_cell_ids]\n",
    "    max_sim = max(sims)\n",
    "    sims_probs = list(map(lambda x:math.exp((x-max_sim) * coef_mul), sims))\n",
    "    sum_probs = sum(sims_probs)\n",
    "    sims_probs = list(map(lambda x:x/sum_probs, sims_probs))\n",
    "    return sims_probs    \n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_order(state: State, nb, graph3_model: MyGraphModel, unixcoder_model, graph3_embeddings, unix_embeddings, graph_weight):\n",
    "    code_cells = nb[nb['cell_type'] == 'code'].reset_index(level='cell_id')\n",
    "    \n",
    "    code_cell_ids = code_cells['cell_id'].values.tolist()\n",
    "    code_cell_ids.append('END')\n",
    "    \n",
    "    cells = []\n",
    "    for pos, cell_id in enumerate(get_code_cells(nb)):\n",
    "        cells.append(OneCell(score=pos+0.5, cell_id=cell_id, cell_type=\"code\"))\n",
    "\n",
    "\n",
    "    samples = gen_samples(state, nb, graph3_model, unixcoder_model, correct_order=None)\n",
    "    batches = split_into_batches(samples, state.config.batch_size)\n",
    "\n",
    "    for samples in batches:\n",
    "        for i in range(len(samples)):\n",
    "            cell_id = samples[i].md_cell_id\n",
    "            \n",
    "            coef = graph_weight\n",
    "            \n",
    "            graph_sims_probs = get_probs_by_embeddings(graph3_embeddings, cell_id, code_cell_ids, graph3_model.coef_mul)\n",
    "            unix_sims_probs = get_probs_by_embeddings(unix_embeddings, cell_id, code_cell_ids, 1000.0)\n",
    "            sims_probs = [a*coef + b*(1 - coef) for (a, b) in zip(graph_sims_probs, unix_sims_probs)]\n",
    "            scores = [0.0] * len(sims_probs)\n",
    "            for i in range(len(sims_probs)):\n",
    "                for j in range(len(sims_probs)):\n",
    "                    scores[j] += abs(i - j) * sims_probs[i]\n",
    "            best_pos = scores.index(min(scores))\n",
    "            \n",
    "            \n",
    "            cells.append(OneCell(score=best_pos, cell_id=cell_id, cell_type=\"markdown\"))\n",
    "\n",
    "    cells.sort(key=lambda x:x.score)\n",
    "    return list(map(lambda c:c.cell_id, cells))\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(state: State, graph3_model: MyGraphModel, unixcoder_model, ensemble_model, save_to_wandb=True):\n",
    "    graph3_model.eval()\n",
    "    unixcoder_model.eval()\n",
    "    ensemble_model.eval()\n",
    "    print('Start testing model:', ensemble_model.name)\n",
    "    if save_to_wandb:\n",
    "        init_wandb(name='test-ensemble-graph3-unix')\n",
    "\n",
    "    df = state.cur_train_nbs\n",
    "    all = df.index.get_level_values(0).unique()\n",
    "\n",
    "    CNT_COEFS = 20\n",
    "    def get_coef(id):\n",
    "        return id / (CNT_COEFS)\n",
    "\n",
    "    sum_scores = {}\n",
    "    \n",
    "    for id in range(CNT_COEFS + 1):\n",
    "        sum_scores[id] = Score(0, 0)\n",
    "\n",
    "    for cnt, nb_id in enumerate(tqdm(all)):\n",
    "        nb = df.loc[nb_id]\n",
    "        graph3_embeddings = graph_model.get_nb_embeddings(state, graph3_model, nb)\n",
    "        unix_embeddings = unixcoder.get_nb_embeddings(state, unixcoder_model, nb)\n",
    "    \n",
    "        for id in range(CNT_COEFS+1):\n",
    "            my_orders = predict_order(state, nb, graph3_model, unixcoder_model, graph3_embeddings, unix_embeddings, graph_weight=get_coef(id))\n",
    "        to_log = {}\n",
    "        \n",
    "        score = metric.calc_nb_score(\n",
    "            my_order=my_orders, correct_order=state.df_orders.loc[nb_id])\n",
    "        sum_scores = Score.merge(sum_scores, score)\n",
    "        to_log['my'] = sum_scores[10].cur_score\n",
    "        if save_to_wandb:\n",
    "            wandb.log(to_log) \n",
    "            \n",
    "        #if cnt >= 100:\n",
    "        #    break\n",
    "\n",
    "    for id in range(CNT_COEFS+1):\n",
    "        print('score of ', get_coef(id), ':', sum_scores[id].cur_score)\n",
    "            \n",
    "    if save_to_wandb:\n",
    "        wandb.finish()\n",
    "\n",
    "\n",
    "test(state, graph3_model, unixcoder_model, ensemble_model, save_to_wandb=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ai4code-train-drive.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d4c7731748faf67a6b8ce01c6c5d4488a25691d99afc96e6b91ec13b7fca11a"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "51d499a2d9f444669353fe695eed76b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74b0bc95556a49c9a4bc80dfe1371d1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51d499a2d9f444669353fe695eed76b6",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de6499ee7ac94760beda7cec7e3fcc66",
      "value": 1
     }
    },
    "778464aabf044263a9c8dc4e88437755": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdcab94b506c4a3fb4b9932465cf4878": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f4d06bd7842a43418bccae854ee08a22",
       "IPY_MODEL_74b0bc95556a49c9a4bc80dfe1371d1d"
      ],
      "layout": "IPY_MODEL_778464aabf044263a9c8dc4e88437755"
     }
    },
    "c963789ee76c461494a518478497f32f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de6499ee7ac94760beda7cec7e3fcc66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e08a3e75f9ad4576942ff4fb28a3e024": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4d06bd7842a43418bccae854ee08a22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c963789ee76c461494a518478497f32f",
      "placeholder": "​",
      "style": "IPY_MODEL_e08a3e75f9ad4576942ff4fb28a3e024",
      "value": "0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\r"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
