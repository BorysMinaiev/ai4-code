{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Im0GS6I0q7Rw",
    "outputId": "7106c86a-dc70-47d8-8777-5af7ff0c7359"
   },
   "outputs": [],
   "source": [
    "%pip install transformers\n",
    "%pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from wandb_helper import init_wandb\n",
    "import wandb_helper\n",
    "import wandb\n",
    "from state import State\n",
    "\n",
    "config = config.get_default_config()\n",
    "wandb_helper.login(config)\n",
    "state = State(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.load_train_nbs_range(from_=100000, to_=101000)\n",
    "# state.load_train_nbs_tail(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_model\n",
    "from graph_model import MyGraphModel\n",
    "\n",
    "\n",
    "graph3_model = MyGraphModel(state, preload_state=\"graph3-model-epoch1.bin\")\n",
    "graph3_model.to(state.device)\n",
    "print('Model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unixcoder\n",
    "\n",
    "unixcoder_model = unixcoder.reload_model(state, \"model-epoch1.5.bin\")\n",
    "print('Unixcoder model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import S\n",
    "from cosine_train import end_token\n",
    "import numpy as np\n",
    "from common import sim, get_probs_by_embeddings, get_best_pos_by_probs\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "\n",
    "from ensembles import gen_samples\n",
    "\n",
    "from tqdm import tqdm\n",
    "import metric\n",
    "from metric import Score\n",
    "from common import get_code_cells, get_markdown_cells, split_into_batches\n",
    "from dataclasses import dataclass\n",
    "import wandb\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "\n",
    "def gen_all_samples(state: State, graph3_model: MyGraphModel, unixcoder_model):\n",
    "    graph3_model.eval()\n",
    "    unixcoder_model.eval()\n",
    "    print('Start generating sample points')\n",
    "    df = state.cur_train_nbs\n",
    "    all = df.index.get_level_values(0).unique()\n",
    "\n",
    "    samples = []\n",
    "\n",
    "    for cnt, nb_id in enumerate(tqdm(all)):\n",
    "        nb = df.loc[nb_id]\n",
    "        samples += gen_samples(state, nb, graph3_model, unixcoder_model, state.df_orders.loc[nb_id])\n",
    "        \n",
    "    return samples\n",
    "\n",
    "samples = gen_all_samples(state, graph3_model, unixcoder_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import ensembles\n",
    "import simple_ensemble\n",
    "\n",
    "def train(state: State, samples, ensemble_model, save_to_wandb=True):\n",
    "    ensemble_model.zero_grad()\n",
    "    ensemble_model.train()\n",
    "    random.seed(787788)\n",
    "    print('Start training ensemble model:', graph3_model.name)\n",
    "    if save_to_wandb:\n",
    "        init_wandb(name='train-ensemble')\n",
    "\n",
    "    random.shuffle(samples)\n",
    "    batches = split_into_batches(samples, state.config.batch_size)\n",
    "\n",
    "    optimizer = AdamW(ensemble_model.parameters(), lr=3e-5, eps=1e-8)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=len(batches))\n",
    "\n",
    "    criterion = torch.nn.L1Loss()\n",
    "    for samples in tqdm(batches):\n",
    "        pred = ensembles.predict(state, ensemble_model, samples)['preds']\n",
    "\n",
    "        target = list(map(lambda s: s.target_pos, samples))\n",
    "        target = torch.tensor(target).to(state.device)\n",
    "\n",
    "        loss = criterion(pred, target)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(ensemble_model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        if save_to_wandb:\n",
    "            wandb.log({'ensemble-loss': loss.item()})\n",
    "\n",
    "    if save_to_wandb:\n",
    "        wandb.finish()\n",
    "\n",
    "\n",
    "ensemble_model = simple_ensemble.SimpleEnsembleModel(state) if state.config.use_simple_ensemble_model else unixcoder.EnsembleModel(state)\n",
    "# train(state, samples, ensemble_model, save_to_wandb=True)\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ensembles\n",
    "\n",
    "@torch.no_grad()\n",
    "def calc_ensemble_dataset_score(state: State, samples, ensemble_model, save_to_wandb=True):\n",
    "    ensemble_model.eval()\n",
    "    if save_to_wandb:\n",
    "        init_wandb(name='test-ensemble-dataset')\n",
    "\n",
    "    batches = split_into_batches(samples, state.config.batch_size)\n",
    "\n",
    "    sum_losses = 0.0\n",
    "    \n",
    "    criterion = torch.nn.L1Loss()\n",
    "    for it, samples in enumerate(tqdm(batches)):\n",
    "        pred = ensembles.predict(state, ensemble_model, samples)\n",
    "\n",
    "        target = list(map(lambda s: s.target_pos, samples))\n",
    "        target = torch.tensor(target).to(state.device)\n",
    "\n",
    "        loss = criterion(pred['preds'], target)\n",
    "        sum_losses += loss.item()\n",
    "\n",
    "        if save_to_wandb:\n",
    "            wandb.log({'test-ensemble-loss': sum_losses / (1 + it)})\n",
    "\n",
    "    if save_to_wandb:\n",
    "        wandb.finish()    \n",
    "    print('sum losses:', sum_losses)\n",
    "    print('av loss:', sum_losses / len(batches))\n",
    "        \n",
    "# calc_ensemble_dataset_score(state, samples, ensemble_model, save_to_wandb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(state, samples, ensemble_model, save_to_wandb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_ensemble_dataset_score(state, samples, ensemble_model, save_to_wandb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model.save('1k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_model = unixcoder.EnsembleModel(state, state_dict='ensemble-model-test.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_ensemble_dataset_score(state, samples, ensemble_model, save_to_wandb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(10):\n",
    "    train(state, samples, ensemble_model, save_to_wandb=False)\n",
    "    calc_ensemble_dataset_score(state, samples, ensemble_model, save_to_wandb=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ai4code-train-drive.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d4c7731748faf67a6b8ce01c6c5d4488a25691d99afc96e6b91ec13b7fca11a"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "51d499a2d9f444669353fe695eed76b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74b0bc95556a49c9a4bc80dfe1371d1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51d499a2d9f444669353fe695eed76b6",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de6499ee7ac94760beda7cec7e3fcc66",
      "value": 1
     }
    },
    "778464aabf044263a9c8dc4e88437755": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdcab94b506c4a3fb4b9932465cf4878": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f4d06bd7842a43418bccae854ee08a22",
       "IPY_MODEL_74b0bc95556a49c9a4bc80dfe1371d1d"
      ],
      "layout": "IPY_MODEL_778464aabf044263a9c8dc4e88437755"
     }
    },
    "c963789ee76c461494a518478497f32f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de6499ee7ac94760beda7cec7e3fcc66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e08a3e75f9ad4576942ff4fb28a3e024": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4d06bd7842a43418bccae854ee08a22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c963789ee76c461494a518478497f32f",
      "placeholder": "​",
      "style": "IPY_MODEL_e08a3e75f9ad4576942ff4fb28a3e024",
      "value": "0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\r"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
