{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Im0GS6I0q7Rw",
    "outputId": "7106c86a-dc70-47d8-8777-5af7ff0c7359"
   },
   "outputs": [],
   "source": [
    "%pip install transformers\n",
    "%pip install wandb\n",
    "%pip install langdetect\n",
    "%pip install sentencepiece\n",
    "%pip install easynmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from easynmt import EasyNMT\n",
    "model = EasyNMT('opus-mt')\n",
    "\n",
    "#Translate a single sentence to German\n",
    "print(model.translate('This is a sentence we want to translate to German', target_lang='de'))\n",
    "\n",
    "#Translate several sentences to German\n",
    "sentences = ['You can define a list with sentences.',\n",
    "             'All sentences are translated to your target language.',\n",
    "             'Note, you could also mix the languages of the sentences.']\n",
    "print(model.translate(sentences, target_lang='de'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from wandb_helper import init_wandb\n",
    "import wandb_helper\n",
    "import wandb\n",
    "from state import State\n",
    "\n",
    "config = config.get_default_config()\n",
    "wandb_helper.login(config)\n",
    "state = State(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#state.load_train_nbs_range(from_=104000, to_=105000)\n",
    "#state.load_train_nbs_tail(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graph_model\n",
    "from graph_model import MyGraphModel\n",
    "\n",
    "\n",
    "graph3_model = MyGraphModel(state, preload_state=\"graph-model-epoch3.bin\")\n",
    "graph3_model.to(state.device)\n",
    "print('Graph3 model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unixcoder\n",
    "\n",
    "unixcoder_model = unixcoder.reload_model(state, \"model-epoch1.5.bin\")\n",
    "print('Unixcoder model loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import metric\n",
    "from metric import Score\n",
    "from common import get_code_cells, get_markdown_cells\n",
    "from dataclasses import dataclass\n",
    "import wandb\n",
    "from graph_model import Sample\n",
    "import numpy as np\n",
    "import torch\n",
    "import ensembles\n",
    "from ensembles import gen_samples\n",
    "from common import split_into_batches, OneCell\n",
    "\n",
    "from cosine_train import end_token\n",
    "from common import sim\n",
    "import math\n",
    "\n",
    "def get_probs_by_embeddings(embeddings, m_cell_id, code_cell_ids, coef_mul):\n",
    "    markdown_emb = embeddings[m_cell_id]\n",
    "    sims = [sim(markdown_emb, embeddings[c]) for c in code_cell_ids]\n",
    "    max_sim = max(sims)\n",
    "    sims_probs = list(map(lambda x:math.exp((x-max_sim) * coef_mul), sims))\n",
    "    sum_probs = sum(sims_probs)\n",
    "    sims_probs = list(map(lambda x:x/sum_probs, sims_probs))\n",
    "    return sims_probs    \n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_order(state: State, nb, graph3_model: MyGraphModel, unixcoder_model, graph3_embeddings, unix_embeddings, graph_weight):\n",
    "    code_cells = nb[nb['cell_type'] == 'code'].reset_index(level='cell_id')\n",
    "    \n",
    "    code_cell_ids = code_cells['cell_id'].values.tolist()\n",
    "    code_cell_ids.append('END')\n",
    "    \n",
    "    cells = []\n",
    "    for pos, cell_id in enumerate(get_code_cells(nb)):\n",
    "        cells.append(OneCell(score=pos+0.5, cell_id=cell_id, cell_type=\"code\"))\n",
    "\n",
    "    markdown_cells = get_markdown_cells(nb)\n",
    "\n",
    "    for cell_id in markdown_cells:            \n",
    "        coef = graph_weight\n",
    "\n",
    "        graph_sims_probs = get_probs_by_embeddings(graph3_embeddings, cell_id, code_cell_ids, graph3_model.coef_mul)\n",
    "        unix_sims_probs = get_probs_by_embeddings(unix_embeddings, cell_id, code_cell_ids, 1000.0)\n",
    "        sims_probs = [a*coef + b*(1 - coef) for (a, b) in zip(graph_sims_probs, unix_sims_probs)]\n",
    "        scores = [0.0] * len(sims_probs)\n",
    "        for i in range(len(sims_probs)):\n",
    "            for j in range(len(sims_probs)):\n",
    "                scores[j] += abs(i - j) * sims_probs[i]\n",
    "        best_pos = scores.index(min(scores))\n",
    "\n",
    "\n",
    "        cells.append(OneCell(score=best_pos, cell_id=cell_id, cell_type=\"markdown\"))\n",
    "\n",
    "    cells.sort(key=lambda x:x.score)\n",
    "    return list(map(lambda c:c.cell_id, cells))\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(state: State, graph3_model: MyGraphModel, unixcoder_model):\n",
    "    graph3_model.eval()\n",
    "    unixcoder_model.eval()\n",
    "    print('Start testing model:')\n",
    "    \n",
    "    df = state.cur_train_nbs\n",
    "    all = df.index.get_level_values(0).unique()\n",
    "\n",
    "    wandb_data = []\n",
    "    \n",
    "    for cnt, nb_id in enumerate(tqdm(all)):\n",
    "        nb = df.loc[nb_id]\n",
    "        graph3_embeddings = graph_model.get_nb_embeddings(state, graph3_model, nb)\n",
    "        unix_embeddings = unixcoder.get_nb_embeddings(state, unixcoder_model, nb)\n",
    "    \n",
    "        my_orders = predict_order(state, nb, graph3_model, unixcoder_model, graph3_embeddings, unix_embeddings, graph_weight=0.5)\n",
    "        score = metric.calc_nb_score(\n",
    "            my_order=my_orders, correct_order=state.df_orders.loc[nb_id])\n",
    "        if score.cur_score < 0.8:\n",
    "            wandb_data.append([nb_id, score.cur_score, len(state.df_orders.loc[nb_id]), len(get_markdown_cells(nb)), len(get_code_cells(nb)), \",\".join(my_orders)])\n",
    "            \n",
    "    init_wandb(name='save-bad-nbs')\n",
    "    my_table = wandb.Table(columns=[\"nb_id\", \"score\", \"cnt cells\", \"cnt markdowns\", \"cnt code\", \"order\"], data=wandb_data)\n",
    "    wandb.log({\"bad runs\": my_table})\n",
    "    wandb.finish()\n",
    "\n",
    "#test(state, graph3_model, unixcoder_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state.easymnt = EasyNMT('opus-mt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "    \n",
    "@torch.no_grad()\n",
    "def test(state: State, graph3_model: MyGraphModel, unixcoder_model, nb_id):\n",
    "    graph3_model.eval()\n",
    "    unixcoder_model.eval()\n",
    "    print('Start testing model:')\n",
    "    \n",
    "    nb = state.load_one_nb(nb_id)\n",
    "   \n",
    "\n",
    "    start = time.time()\n",
    "    graph3_embeddings = graph_model.get_nb_embeddings(state, graph3_model, nb)\n",
    "    end = time.time()\n",
    "    print('time:', end - start)\n",
    "    unix_embeddings = unixcoder.get_nb_embeddings(state, unixcoder_model, nb)\n",
    "\n",
    "    my_orders = predict_order(state, nb, graph3_model, unixcoder_model, graph3_embeddings, unix_embeddings, graph_weight=1.0)\n",
    "    score = metric.calc_nb_score(\n",
    "        my_order=my_orders, correct_order=state.df_orders.loc[nb_id])\n",
    "    print(score)\n",
    "    \n",
    "#state.config.clean_html = False\n",
    "\n",
    "test(state, graph3_model, unixcoder_model, nb_id='d1ef1808a5d61a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from language import detect_nb_lang\n",
    "nb_ids = ['3a1da227ab17a0', '961b63b04a9637', 'dbfe8b7e5b2226', 'da8f893b2ec723', \n",
    "    'd1ef1808a5d61a', '2a829655be3fab', '241f611e38f2b2', '6207afb54d4159', '97db9116552332', '2fa216ddc5c8cd', '5ca09e62dd4dd0']\n",
    "# nb_ids = ['97db9116552332']\n",
    "for nb_id in nb_ids:\n",
    "    nb = state.load_one_nb(nb_id)\n",
    "    lang = detect_nb_lang(nb)\n",
    "    print('nb_id:', nb_id, 'lang:', lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from language import Translator, get_translator\n",
    "\n",
    "marian_ru_en = get_translator('ru', 'en')\n",
    "marian_ru_en.translate(\n",
    "    ['что слишком сознавать — это болезнь, настоящая, полная болезнь.'])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ai4code-train-drive.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d4c7731748faf67a6b8ce01c6c5d4488a25691d99afc96e6b91ec13b7fca11a"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "51d499a2d9f444669353fe695eed76b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74b0bc95556a49c9a4bc80dfe1371d1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51d499a2d9f444669353fe695eed76b6",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de6499ee7ac94760beda7cec7e3fcc66",
      "value": 1
     }
    },
    "778464aabf044263a9c8dc4e88437755": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdcab94b506c4a3fb4b9932465cf4878": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f4d06bd7842a43418bccae854ee08a22",
       "IPY_MODEL_74b0bc95556a49c9a4bc80dfe1371d1d"
      ],
      "layout": "IPY_MODEL_778464aabf044263a9c8dc4e88437755"
     }
    },
    "c963789ee76c461494a518478497f32f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de6499ee7ac94760beda7cec7e3fcc66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e08a3e75f9ad4576942ff4fb28a3e024": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4d06bd7842a43418bccae854ee08a22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c963789ee76c461494a518478497f32f",
      "placeholder": "​",
      "style": "IPY_MODEL_e08a3e75f9ad4576942ff4fb28a3e024",
      "value": "0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\r"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
