{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "config = config.get_local_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IDJEubbHqgW_",
    "outputId": "82ebe350-24fb-4e24-f55f-5e1dcc0162ad"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 352
    },
    "id": "6tlXn4X6jBj5",
    "outputId": "91b25acd-1c94-4897-feba-dd6de5d406c6",
    "papermill": {
     "duration": 0.056058,
     "end_time": "2022-05-22T21:58:28.980447",
     "exception": false,
     "start_time": "2022-05-22T21:58:28.924389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Im0GS6I0q7Rw",
    "outputId": "7106c86a-dc70-47d8-8777-5af7ff0c7359"
   },
   "outputs": [],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f_ZRQzR-jBj7",
    "papermill": {
     "duration": 6.489575,
     "end_time": "2022-05-22T21:58:39.682208",
     "exception": false,
     "start_time": "2022-05-22T21:58:33.192633",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import unixcoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": false,
    "id": "JXC0KCtojBj9",
    "papermill": {
     "duration": 11.138926,
     "end_time": "2022-05-22T21:58:50.848367",
     "exception": false,
     "start_time": "2022-05-22T21:58:39.709441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from common import reload_model\n",
    "\n",
    "reload_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from state import State\n",
    "\n",
    "state = State()\n",
    "state.load_df_orders(config)\n",
    "state.load_test_nbs(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ednqpYHvDoS",
    "outputId": "f47a6b72-5323-4992-849f-aea79a9c6149"
   },
   "outputs": [],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IOoaqyZvjBkB",
    "outputId": "0a520626-cf9f-4eb3-c894-b2d3ade5c080",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from wandb_helper import init_wandb\n",
    "import wandb_helper\n",
    "wandb_helper.login(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZQyQfs3QDpqu"
   },
   "outputs": [],
   "source": [
    "max_batch_size = 60\n",
    "minibatch_size = 8\n",
    "default_mul = 1000\n",
    "end_token = 'END'\n",
    "\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from dataclasses import dataclass\n",
    "from torch.optim import AdamW\n",
    "import random\n",
    "random.seed(787788)\n",
    "\n",
    "@dataclass\n",
    "class MiniBatch:\n",
    "    markdowns:list\n",
    "    code:list\n",
    "    correct_idx:list # for each markdown store idx in code\n",
    "    max_len_cache:int\n",
    "        \n",
    "    def append(self, cur_markdown, cur_code):\n",
    "        self.markdowns.append(cur_markdown)\n",
    "        if cur_code in self.code:\n",
    "            self.correct_idx.append(self.code.index(cur_code))\n",
    "        else:\n",
    "            self.code.append(cur_code)\n",
    "            self.correct_idx.append(len(self.code) - 1)\n",
    "        \n",
    "        \n",
    "    def get_max_len(self):\n",
    "        if self.max_len_cache == 0:\n",
    "            texts_len = [len(t) for t in (self.markdowns + self.code)]\n",
    "            self.max_len_cache = max(texts_len)\n",
    "        return self.max_len_cache\n",
    "    \n",
    "    def cnt(self):\n",
    "        return len(self.markdowns) + len(self.code)\n",
    "    \n",
    "@dataclass \n",
    "class Batch:\n",
    "    mini:list\n",
    "    sum_cnt:int\n",
    "    \n",
    "    def append(self, mini_batch):\n",
    "        self.mini.append(mini_batch)\n",
    "        self.sum_cnt += mini_batch.cnt()\n",
    "        \n",
    "    def get_all_tokens(self):\n",
    "        all = []\n",
    "        for mini in self.mini:\n",
    "            all += mini.markdowns \n",
    "            all += mini.code\n",
    "        return get_texts_tokens(all)\n",
    "        \n",
    "@dataclass\n",
    "class Sample:\n",
    "    markdown:str\n",
    "    code:str\n",
    "    \n",
    "\n",
    "\n",
    "def gen_batches(all):\n",
    "    minibatches = []\n",
    "    for id, nb_id in enumerate(tqdm(all)):\n",
    "        nb = df.loc[nb_id]\n",
    "        correct_order = df_orders.loc[nb_id]\n",
    "        correct_order.append(end_token)\n",
    "        markdown_cell_ids = get_markdown_cells(nb)\n",
    "        \n",
    "        def get_code(cell_id):\n",
    "            if cell_id == end_token:\n",
    "                return end_token\n",
    "            return nb.loc[cell_id]['source']\n",
    "        \n",
    "        samples = []\n",
    "        for pos, cell_id in enumerate(correct_order):\n",
    "            if cell_id in markdown_cell_ids:\n",
    "                next_code_cell = None\n",
    "                for next_cell in correct_order[pos:]:\n",
    "                    if next_cell not in markdown_cell_ids:\n",
    "                        next_code_cell = next_cell\n",
    "                        break\n",
    "                assert next_code_cell != None\n",
    "                samples.append(Sample(markdown=nb.loc[cell_id]['source'], code=get_code(next_code_cell)))\n",
    "        random.shuffle(samples)\n",
    "        num_chunks = (len(samples) + minibatch_size - 1) // minibatch_size\n",
    "        \n",
    "        for batch_samples in np.array_split(samples, num_chunks):\n",
    "            batch = MiniBatch(markdowns=[], code=[], correct_idx=[], max_len_cache=0)\n",
    "            for sample in batch_samples:\n",
    "                batch.append(sample.markdown, sample.code)\n",
    "            minibatches.append(batch)\n",
    "    print('Sorting minibatches')\n",
    "    minibatches.sort(key=lambda x:x.get_max_len())\n",
    "    print('Done sorting minibatches')\n",
    "    \n",
    "    batches = []\n",
    "    for b in minibatches:\n",
    "        if len(batches) == 0 or batches[-1].sum_cnt + b.cnt() > max_batch_size:\n",
    "            batches.append(Batch(mini=[], sum_cnt=0))\n",
    "        batches[-1].append(b) \n",
    "        \n",
    "    random.shuffle(batches)        \n",
    "    return batches\n",
    "\n",
    "def train_on_batch(batch, model, optimizer, scheduler):\n",
    "    tokens = batch.get_all_tokens()\n",
    "    embeddings = model(tokens)\n",
    "    \n",
    "    \n",
    "    markdown_vec = []\n",
    "    code_vec = []\n",
    "    expected_order = []\n",
    "    \n",
    "    shift = 0\n",
    "    code_shift = 0\n",
    "    \n",
    "    for mini in batch.mini:\n",
    "        markdown_vec += embeddings[shift:shift+len(mini.markdowns)]\n",
    "        code_vec += embeddings[shift+len(mini.markdowns):shift+mini.cnt()]\n",
    "        shift += mini.cnt()\n",
    "        expected_order += [(x + code_shift) for x in mini.correct_idx]\n",
    "        code_shift += len(mini.code)\n",
    "        \n",
    "    scores = torch.einsum(\"ab,cb->ac\", torch.stack(markdown_vec), torch.stack(code_vec)) * default_mul\n",
    "\n",
    "    expected_order = torch.tensor(expected_order).to(device)\n",
    "\n",
    "    loss_fct = CrossEntropyLoss()\n",
    "    loss = loss_fct(scores, expected_order)\n",
    "\n",
    "    loss.backward() \n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    scheduler.step() \n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "def run_train_all_new():\n",
    "    print('Start training')\n",
    "    all = df.index.get_level_values(0).unique()\n",
    "    print('Start generating batches...')\n",
    "    batches = gen_batches(all)\n",
    "    print('Generated batches:', len(batches))\n",
    "    \n",
    "    reload_model(preload=\"model-100k-mul1000-all-bs60-8.bin\")\n",
    "    model = Model(unixcoder_model)\n",
    "    model.zero_grad()\n",
    "    model.train()\n",
    "\n",
    "    \n",
    "\n",
    "    learning_rate = 3e-5\n",
    "    epochs = 1\n",
    "    steps = len(batches)\n",
    "\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = steps * epochs)\n",
    "\n",
    "    \n",
    "    start_time = time.time()\n",
    "    last_saved_time = start_time\n",
    "    save_every_s = 40 * 60\n",
    "    max_run_s = 12 * 3600\n",
    "    \n",
    "    init_wandb(name=(str(len(all) / 1000) + \"k,lr=3e-5,mul-\" + str(default_mul)+\",all-bs=\"+str(max_batch_size)+\"-\"+str(minibatch_size)))\n",
    "    w_loss = 0.0\n",
    "    \n",
    "    for id, batch in enumerate(tqdm(batches)):\n",
    "        cur_loss = train_on_batch(batch, model, optimizer, scheduler)\n",
    "        \n",
    "        w_loss = w_loss * 0.95 + cur_loss * 0.05\n",
    "        wandb.log({'loss': w_loss})\n",
    "        \n",
    "        cur_time = time.time()\n",
    "        if cur_time - last_saved_time > save_every_s:\n",
    "            last_saved_time = cur_time\n",
    "            save_model(model, id)\n",
    "        \n",
    "        if cur_time - start_time > max_run_s:\n",
    "            print('Finishing early because of timeout')\n",
    "            break\n",
    "            \n",
    "    wandb.finish()\n",
    "    save_model(model, \"final\")\n",
    "  \n",
    "    \n",
    "run_train_all_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_train_nbs(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "id": "gbgweprwjBkB",
    "outputId": "986af571-5d91-4fc1-fe22-cccf4cb30113",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def num_test_inputs():\n",
    "    return len(test_df.index.get_level_values(0).unique())\n",
    "\n",
    "# if num_test_inputs() != 4:\n",
    "if not is_interactive_mode() or True:\n",
    "    print('Going to generate model...')\n",
    "    # 2000 - half an hour\n",
    "    load_train_nbs(10_000)\n",
    "    run_train_all_new()\n",
    "\n",
    "# save_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H-Y-9x8yP694"
   },
   "outputs": [],
   "source": [
    "!mv model-final.bin model-epoch2-10k.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/home/gdrive upload -p 12wE_l-hW_ScKnP9l-cpWWRTtuC5fZD7c model-epoch2-10k.bin\n",
    "# !/home/gdrive upload -p 12wE_l-hW_ScKnP9l-cpWWRTtuC5fZD7c model-54321.bin\n",
    "# !/home/gdrive upload -p 12wE_l-hW_ScKnP9l-cpWWRTtuC5fZD7c model-43403.bin\n",
    "# !/home/gdrive upload -p 12wE_l-hW_ScKnP9l-cpWWRTtuC5fZD7c model-37926.bin\n",
    "# !/home/gdrive upload -p 12wE_l-hW_ScKnP9l-cpWWRTtuC5fZD7c model-32433.bin\n",
    "# !/home/gdrive upload -p 12wE_l-hW_ScKnP9l-cpWWRTtuC5fZD7c model-26960.bin\n",
    "# !/home/gdrive upload -p 12wE_l-hW_ScKnP9l-cpWWRTtuC5fZD7c model-21506.bin\n",
    "# !/home/gdrive upload -p 12wE_l-hW_ScKnP9l-cpWWRTtuC5fZD7c model-16067.bin\n",
    "# !/home/gdrive upload -p 12wE_l-hW_ScKnP9l-cpWWRTtuC5fZD7c model-15334.bin\n",
    "# !/home/gdrive upload -p 12wE_l-hW_ScKnP9l-cpWWRTtuC5fZD7c model-10691.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z7aYHOp0zvIh"
   },
   "outputs": [],
   "source": [
    "# !cp model-20312.bin drive/MyDrive/ai4-code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kW_ZXuFgHSO"
   },
   "outputs": [],
   "source": [
    "!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "31bQA5YWgRlv"
   },
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util, InputExample, evaluation, losses\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7hQOsZ_DaUIE"
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "import random\n",
    "\n",
    "@dataclass\n",
    "class Part:\n",
    "  is_code: bool\n",
    "  ids: List[str]\n",
    "\n",
    "def split_parts(nb_id):\n",
    "  parts = []\n",
    "  correct_order = df_orders[nb_id]\n",
    "  nb = df.loc[nb_id]\n",
    "  i = 0\n",
    "  while i != len(correct_order):\n",
    "    j = i\n",
    "    cur_cell_type = nb.loc[correct_order[i]]['cell_type']\n",
    "    ids = []\n",
    "    while j != len(correct_order) and nb.loc[correct_order[j]]['cell_type'] == cur_cell_type:\n",
    "      ids.append(correct_order[j])\n",
    "      j = j + 1\n",
    "    parts.append(Part(cur_cell_type=='code', ids))\n",
    "    i = j\n",
    "  return parts\n",
    "\n",
    "def only_code_parts(parts):\n",
    "  return list(filter(lambda p: p.is_code, parts))\n",
    "\n",
    "def only_markdown_parts(parts):\n",
    "  return list(filter(lambda p: not p.is_code, parts))  \n",
    "\n",
    "@dataclass\n",
    "class MmDataset:\n",
    "  same_group: List[List[str]]\n",
    "  diff_group: List[List[str]]\n",
    "\n",
    "def generate_mm_dataset():\n",
    "  print('Generating markdown-markdown dataset')\n",
    "\n",
    "  all = df.index.get_level_values(0).unique()\n",
    "\n",
    "  same_group = []\n",
    "  diff_group = []\n",
    "\n",
    "  for nb_id in tqdm(all):\n",
    "    # print('nb_id:', nb_id)\n",
    "    nb = df.loc[nb_id]\n",
    "    def get_text(id):\n",
    "      return nb.loc[id]['source']\n",
    "    parts = split_parts(nb_id)\n",
    "    markdown_parts = only_markdown_parts(parts)\n",
    "    for i in range(len(markdown_parts)):\n",
    "      part = markdown_parts[i]\n",
    "      if len(part.ids) > 1 and random.getrandbits(1):\n",
    "        c1,c2 = random.sample(part.ids, 2)\n",
    "        same_group.append([get_text(c1), get_text(c2)])\n",
    "      else:\n",
    "        j = random.randint(0, len(markdown_parts) - 1)\n",
    "        if j != i:\n",
    "          c1 = random.choice(part.ids)\n",
    "          c2 = random.choice(markdown_parts[j].ids)\n",
    "          diff_group.append([get_text(c1), get_text(c2)])\n",
    "\n",
    "  return MmDataset(same_group, diff_group)\n",
    "  \n",
    "\n",
    "\n",
    "# dataloader = generate_mm_dataset()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LrvmJOeiib71"
   },
   "outputs": [],
   "source": [
    "def mm_dataloader():\n",
    "  mm_dataset = generate_mm_dataset()\n",
    "  train_examples = [InputExample(texts=texts, label=1.0) for texts in mm_dataset.same_group] + [InputExample(texts=texts, label=0.0) for texts in mm_dataset.diff_group]\n",
    "  train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=8)\n",
    "  return train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Exf1FRDhrNe"
   },
   "outputs": [],
   "source": [
    "# model = SentenceTransformer('nq-distilbert-base-v1') # TODO: change model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hzPijqX3lTwo"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import paired_cosine_distances\n",
    "import seaborn as sns\n",
    "\n",
    "def test():\n",
    "  mm_dataset = generate_mm_dataset()\n",
    "\n",
    "  first  = [x[0] for x in mm_dataset.same_group] + [x[0] for x in mm_dataset.diff_group]\n",
    "  second = [x[1] for x in mm_dataset.same_group] + [x[1] for x in mm_dataset.diff_group]\n",
    "\n",
    "  embeddings1 = model.encode(first, batch_size= 8, show_progress_bar=True, convert_to_numpy=True)\n",
    "  embeddings2 = model.encode(second, batch_size= 8, show_progress_bar=True, convert_to_numpy=True)\n",
    "\n",
    "  labels = [1]*len(mm_dataset.same_group) + [0]*len(mm_dataset.diff_group)\n",
    "\n",
    "  cosine_scores = 1 - (paired_cosine_distances(embeddings1, embeddings2))\n",
    "\n",
    "  sz1 = len(mm_dataset.same_group)\n",
    "  print(cosine_scores[:sz1].mean())\n",
    "  print(cosine_scores[sz1:].mean())\n",
    "\n",
    "\n",
    "  # sns.distplot(cosine_scores[:sz1], label = \"1\")\n",
    "  # sns.distplot(cosine_scores[sz1:], label = \"0\")\n",
    "\n",
    "  tmp_df = pd.DataFrame({\"s1\":first,\"s2\":second, \"lbl\":labels, \"cos\": cosine_scores}).assign(delta = lambda x: np.abs(x.lbl - x.cos)).sort_values(\"delta\", ascending=True)\n",
    "\n",
    "  # getting correct incorrect match\n",
    "  scores = []\n",
    "  for x in range(10,90,1):\n",
    "      scores.append( ( x/100, tmp_df.assign(pred = lambda xx: xx.cos > x/100 )\\\n",
    "            .assign(correct = lambda xxx: xxx.pred == xxx.lbl).correct.mean() ) )\n",
    "      \n",
    "  best_score = sorted(scores, key = lambda x: x[1], reverse = True)[0]\n",
    "  print(\"Best accuracy of {} using threshold {}\".format(best_score[1], best_score[0])) \n",
    "\n",
    "  print(\"\\nBad predictions - \")\n",
    "  return tmp_df.head(50)\n",
    "            \n",
    "\n",
    "\n",
    "# test()\n",
    "# print('End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A6WKtP0eqBlh"
   },
   "outputs": [],
   "source": [
    "# train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "# train_dataloader = mm_dataloader()\n",
    "\n",
    "# #Tune the model\n",
    "# model.fit(train_objectives=[(train_dataloader, train_loss)], \n",
    "#           epochs=1, \n",
    "#           warmup_steps= 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qcCFfSAqQeq"
   },
   "outputs": [],
   "source": [
    "# test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cdF3OXaQg8H6"
   },
   "outputs": [],
   "source": [
    "!pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-IlVR1YVdCAP"
   },
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from langdetect import detect\n",
    "\n",
    "def detect_lang(x):\n",
    "  try:\n",
    "    return detect(x)\n",
    "  except:\n",
    "    return 'other'\n",
    "\n",
    "def run_train_all():\n",
    "    all = df.index.get_level_values(0).unique()\n",
    "    texts = []\n",
    "    tokenized = []\n",
    "    langs = []\n",
    "    for id, nb_id in enumerate(tqdm(all)):\n",
    "      nb = get_nb_by_id(nb_id)\n",
    "      markdown_cell_ids = get_markdown_cells(nb)\n",
    "      cell_id = random.choice(markdown_cell_ids)\n",
    "      t = nb.loc[cell_id]['source'].lower()\n",
    "      texts.append(t)\n",
    "      langs.append(detect_lang(t))\n",
    "      tokenized.append(unixcoder_model.tokenizer.tokenize(t))\n",
    "\n",
    "    return pd.DataFrame(data={'text':texts, 'lang' : langs, 'tokenized':tokenized})\n",
    "\n",
    " \n",
    "# run_train_all()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ai4code-train-drive.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.7.13 ('kaggle')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d4c7731748faf67a6b8ce01c6c5d4488a25691d99afc96e6b91ec13b7fca11a"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "51d499a2d9f444669353fe695eed76b6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74b0bc95556a49c9a4bc80dfe1371d1d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_51d499a2d9f444669353fe695eed76b6",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de6499ee7ac94760beda7cec7e3fcc66",
      "value": 1
     }
    },
    "778464aabf044263a9c8dc4e88437755": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdcab94b506c4a3fb4b9932465cf4878": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f4d06bd7842a43418bccae854ee08a22",
       "IPY_MODEL_74b0bc95556a49c9a4bc80dfe1371d1d"
      ],
      "layout": "IPY_MODEL_778464aabf044263a9c8dc4e88437755"
     }
    },
    "c963789ee76c461494a518478497f32f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "de6499ee7ac94760beda7cec7e3fcc66": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e08a3e75f9ad4576942ff4fb28a3e024": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4d06bd7842a43418bccae854ee08a22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c963789ee76c461494a518478497f32f",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_e08a3e75f9ad4576942ff4fb28a3e024",
      "value": "0.008 MB of 0.008 MB uploaded (0.000 MB deduped)\r"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
